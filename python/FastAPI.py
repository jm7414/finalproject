"""
Missing Person Destination Prediction API - Complete Version
ì‹¤ì¢…ì ëª©ì ì§€ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (ê²€ì¦ ê¸°ëŠ¥ í¬í•¨)

Features:
- BallTree ê¸°ë°˜ ë¹ ë¥¸ ë„ë¡œ ë…¸ë“œ ìŠ¤ëƒ…
- ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„
- ì„ í˜¸ ê²½ë¡œ ë°˜ì˜
- ì§€ë¦¬ì  ë¶„ì‚° ê³ ë ¤
- ëª¨ë¸ ê²€ì¦ API
"""

from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Optional
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
from sqlalchemy import Table, Column, Integer, Float, DateTime, MetaData, select, and_
from sqlalchemy.orm import declarative_base
from datetime import datetime, timedelta
import os
import numpy as np
import pandas as pd
import hdbscan
import asyncio
from concurrent.futures import ThreadPoolExecutor
from collections import Counter
import osmnx as ox
import networkx as nx
from sklearn.neighbors import BallTree

# =============================================================================
# Configuration
# =============================================================================

os.environ['LC_ALL'] = 'C.UTF-8'
os.environ['LANG'] = 'en_US.UTF-8'

DATABASE_URL = "postgresql+asyncpg://postgres:rootroot@localhost:5432/finalproject"

engine = create_async_engine(
    DATABASE_URL,
    echo=False,
    pool_pre_ping=True,
    connect_args={"ssl": False}
)

SessionLocal = async_sessionmaker(engine, expire_on_commit=False)
Base = declarative_base()

executor = ThreadPoolExecutor(max_workers=4)

# Caches
ROAD_NETWORK_CACHE = {}
BALLTREE_CACHE = {}

# =============================================================================
# FastAPI App
# =============================================================================

app = FastAPI(
    title="ì‹¤ì¢…ì ëª©ì ì§€ ì˜ˆì¸¡ API (ì™„ì „íŒ)",
    description="ê²€ì¦ ê¸°ëŠ¥ í¬í•¨ ì‹¤ì¢…ì ê²½ë¡œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ",
    version="11.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =============================================================================
# Pydantic Models
# =============================================================================

class Waypoint(BaseModel):
    lat: float
    lon: float
    node_id: Optional[int] = None


class Destination(BaseModel):
    destination_id: int
    latitude: float
    longitude: float
    visit_count: int
    total_gps_records: int
    distance_meters: float
    cluster_stability: float
    waypoints: List[Waypoint]
    preference_score: float
    route_method: str
    name: Optional[str] = None


class LastKnownLocation(BaseModel):
    latitude: float
    longitude: float
    time: str


class PredictionResponse(BaseModel):
    user_no: int
    missing_time: str
    last_known_location: LastKnownLocation
    analysis_period_days: int
    session_gap_minutes: int
    time_filtered_records: int
    total_clusters_found: int
    destinations_by_distance: Dict[str, List[Destination]]
    data_sufficiency: str = Field(description="ë°ì´í„° ì¶©ë¶„ì„± (yes/no) - 28ì¼ ì´ìƒ ë°ì´í„° ê¸°ì¤€")
    total_gps_records: int = Field(description="ì „ì²´ GPS ë ˆì½”ë“œ ìˆ˜")


class ValidationMetrics(BaseModel):
    total_test_cases: int
    hit_rate_500m: float = Field(description="500m ì´ë‚´ ì ì¤‘ë¥ ")
    hit_rate_1000m: float = Field(description="1000m ì´ë‚´ ì ì¤‘ë¥ ")
    hit_rate_1500m: float = Field(description="1500m ì´ë‚´ ì ì¤‘ë¥ ")
    average_distance_error: float = Field(description="í‰ê·  ê±°ë¦¬ ì˜¤ì°¨ (ë¯¸í„°)")
    median_distance_error: float = Field(description="ì¤‘ê°„ê°’ ê±°ë¦¬ ì˜¤ì°¨ (ë¯¸í„°)")
    route_similarity_score: float = Field(description="ê²½ë¡œ ìœ ì‚¬ë„ (0~1)")


class TestCase(BaseModel):
    test_time: str
    predicted_location: Dict[str, float]
    actual_location: Dict[str, float]
    distance_error: float
    hit_500m: bool
    hit_1000m: bool
    hit_1500m: bool


class ValidationResponse(BaseModel):
    user_no: int
    validation_period: str
    metrics: ValidationMetrics
    test_cases: List[TestCase]


# =============================================================================
# Utility Functions
# =============================================================================

def haversine_distance(lat1, lon1, lat2, lon2):
    """Haversine ê±°ë¦¬ ê³„ì‚° (ë¯¸í„°)"""
    R = 6371000
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    return R * c


def get_road_network_sync(center_lat, center_lon, radius_m=2000):
    """OSMnx ë„ë¡œë§ ë‹¤ìš´ë¡œë“œ (ë™ê¸°, ìºì‹œ)"""
    cache_key = f"{center_lat:.4f}_{center_lon:.4f}_{radius_m}"
    
    if cache_key in ROAD_NETWORK_CACHE:
        print(f"  âœ… ìºì‹œëœ ë„ë¡œë§ ì‚¬ìš©")
        return ROAD_NETWORK_CACHE[cache_key]
    
    try:
        print(f"  ğŸŒ OSMnx ë„ë¡œë§ ë‹¤ìš´ë¡œë“œ... (ë°˜ê²½ {radius_m}m)")
        G = ox.graph_from_point(
            (center_lat, center_lon),
            dist=radius_m,
            network_type='walk',
            simplify=True
        )
        ROAD_NETWORK_CACHE[cache_key] = G
        print(f"  âœ… ì™„ë£Œ: {G.number_of_nodes()}ê°œ ë…¸ë“œ")
        return G
    except Exception as e:
        print(f"  âš ï¸ OSMnx ì‹¤íŒ¨: {e}")
        return None


async def get_road_network(center_lat, center_lon, radius_m=2000):
    """ë¹„ë™ê¸° ë²„ì „"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        executor,
        get_road_network_sync,
        center_lat, center_lon, radius_m
    )


def build_balltree(G):
    """BallTree ì¸ë±ìŠ¤ êµ¬ì¶• (ë¹ ë¥¸ ìµœê·¼ì ‘ ë…¸ë“œ ê²€ìƒ‰)"""
    cache_key = id(G)
    
    if cache_key in BALLTREE_CACHE:
        return BALLTREE_CACHE[cache_key]
    
    nodes = []
    coords = []
    
    for node, data in G.nodes(data=True):
        nodes.append(node)
        coords.append([np.radians(data['y']), np.radians(data['x'])])
    
    coords = np.array(coords)
    tree = BallTree(coords, metric='haversine')
    
    result = (tree, nodes, coords)
    BALLTREE_CACHE[cache_key] = result
    
    return result


def snap_to_nearest_node_fast(G, tree_data, lat, lon):
    """BallTreeë¡œ ë¹ ë¥¸ ë…¸ë“œ ìŠ¤ëƒ…"""
    if G is None or tree_data is None:
        return None
    
    try:
        tree, nodes, coords = tree_data
        query_point = np.radians([[lat, lon]])
        dist, idx = tree.query(query_point, k=1)
        
        nearest_idx = idx[0][0]
        nearest_node = nodes[nearest_idx]
        
        node_data = G.nodes[nearest_node]
        return (int(nearest_node), float(node_data['y']), float(node_data['x']))
    except Exception as e:
        print(f"    âš ï¸ ìŠ¤ëƒ… ì‹¤íŒ¨: {e}")
        return None


def sample_gps_data(gps_data, max_samples=500):
    """GPS ë°ì´í„° ìƒ˜í”Œë§"""
    if len(gps_data) <= max_samples:
        return gps_data
    
    indices = np.linspace(0, len(gps_data) - 1, max_samples, dtype=int)
    sampled = [gps_data[i] for i in indices]
    
    return sampled


def generate_road_snapped_waypoints_sync(G, tree_data, gps_data, start_lat, start_lon, end_lat, end_lon):
    """ìµœì í™”ëœ ë„ë¡œ ë…¸ë“œ ê¸°ë°˜ waypoint ìƒì„±"""
    if G is None or tree_data is None:
        waypoints = [
            {"lat": float(round(start_lat, 6)), "lon": float(round(start_lon, 6)), "node_id": None},
            {"lat": float(round(end_lat, 6)), "lon": float(round(end_lon, 6)), "node_id": None}
        ]
        return waypoints, 0.0, "straight_line"
    
    start_node_data = snap_to_nearest_node_fast(G, tree_data, start_lat, start_lon)
    end_node_data = snap_to_nearest_node_fast(G, tree_data, end_lat, end_lon)
    
    if not start_node_data or not end_node_data:
        waypoints = [
            {"lat": float(round(start_lat, 6)), "lon": float(round(start_lon, 6)), "node_id": None},
            {"lat": float(round(end_lat, 6)), "lon": float(round(end_lon, 6)), "node_id": None}
        ]
        return waypoints, 0.0, "straight_line"
    
    start_node_id, start_node_lat, start_node_lon = start_node_data
    end_node_id, end_node_lat, end_node_lon = end_node_data
    
    try:
        route = nx.shortest_path(G, start_node_id, end_node_id, weight='length')
    except (nx.NetworkXNoPath, nx.NodeNotFound):
        waypoints = [
            {"lat": float(round(start_node_lat, 6)), "lon": float(round(start_node_lon, 6)), "node_id": start_node_id},
            {"lat": float(round(end_node_lat, 6)), "lon": float(round(end_node_lon, 6)), "node_id": end_node_id}
        ]
        return waypoints, 0.0, "straight_line"
    
    sampled_gps = sample_gps_data(gps_data, max_samples=500)
    
    node_visit_count = Counter()
    for gps_lat, gps_lon, gps_time in sampled_gps:
        node_data = snap_to_nearest_node_fast(G, tree_data, gps_lat, gps_lon)
        if node_data:
            node_id = node_data[0]
            node_visit_count[node_id] += 1
    
    frequent_nodes = []
    for node_id in route:
        if node_id == start_node_id or node_id == end_node_id:
            continue
        
        visit_count = node_visit_count.get(node_id, 0)
        if visit_count > 0:
            node_data = G.nodes[node_id]
            frequent_nodes.append((node_id, node_data['y'], node_data['x'], visit_count))
    
    frequent_nodes.sort(key=lambda x: x[3], reverse=True)
    selected_nodes = frequent_nodes[:3]
    
    if selected_nodes:
        node_order = {node_id: idx for idx, node_id in enumerate(route)}
        selected_nodes.sort(key=lambda x: node_order.get(x[0], 0))
    
    waypoints = []
    
    waypoints.append({
        "lat": float(round(start_node_lat, 6)),
        "lon": float(round(start_node_lon, 6)),
        "node_id": start_node_id
    })
    
    for node_id, lat, lon, visit_count in selected_nodes:
        waypoints.append({
            "lat": float(round(lat, 6)),
            "lon": float(round(lon, 6)),
            "node_id": int(node_id)
        })
    
    waypoints.append({
        "lat": float(round(end_node_lat, 6)),
        "lon": float(round(end_node_lon, 6)),
        "node_id": end_node_id
    })
    
    total_visits = sum([x[3] for x in selected_nodes])
    preference_score = min(1.0, total_visits / 30)
    
    return waypoints, preference_score, "road_network"


async def generate_road_snapped_waypoints(G, tree_data, gps_data, start_lat, start_lon, end_lat, end_lon):
    """ë¹„ë™ê¸° ë²„ì „"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        executor,
        generate_road_snapped_waypoints_sync,
        G, tree_data, gps_data, start_lat, start_lon, end_lat, end_lon
    )


def filter_by_similar_time(gps_data, target_time, time_window_hours=3):
    """ì‹œê°„ëŒ€ë³„ í•„í„°ë§"""
    target_hour = target_time.hour
    
    filtered = []
    for lat, lon, record_time in gps_data:
        record_hour = record_time.hour
        hour_diff = abs(record_hour - target_hour)
        if hour_diff > 12:
            hour_diff = 24 - hour_diff
        
        if hour_diff <= time_window_hours:
            filtered.append((lat, lon, record_time))
    
    return filtered


def select_diverse_clusters(clusters, max_count=3, min_separation_m=200):
    """ì§€ë¦¬ì  ë¶„ì‚° ê³ ë ¤ í´ëŸ¬ìŠ¤í„° ì„ íƒ"""
    selected = []
    sorted_clusters = sorted(clusters, key=lambda x: x[2], reverse=True)
    
    for cluster in sorted_clusters:
        if len(selected) >= max_count:
            break
        
        cluster_lat, cluster_lon = cluster[0], cluster[1]
        
        too_close = False
        for selected_cluster in selected:
            selected_lat, selected_lon = selected_cluster[0], selected_cluster[1]
            dist = haversine_distance(cluster_lat, cluster_lon, selected_lat, selected_lon)
            
            if dist < min_separation_m:
                too_close = True
                break
        
        if not too_close:
            selected.append(cluster)
    
    return selected


def count_visit_sessions(timestamps, gap_threshold_minutes=30):
    """ë°©ë¬¸ ì„¸ì…˜ ì¹´ìš´íŠ¸"""
    if len(timestamps) == 0:
        return 0
    
    sorted_times = sorted(timestamps)
    session_count = 1
    
    for i in range(1, len(sorted_times)):
        time_gap = (sorted_times[i] - sorted_times[i-1]).total_seconds() / 60
        if time_gap > gap_threshold_minutes:
            session_count += 1
    
    return session_count


def find_frequent_locations_with_sessions_sync(gps_data, last_known_coords, max_search_radius_m,
                                               min_visits, session_gap_minutes, min_cluster_size):
    """HDBSCAN í´ëŸ¬ìŠ¤í„°ë§"""
    last_lat, last_lon = last_known_coords
    
    if len(gps_data) < min_visits:
        return []
    
    nearby_gps = []
    for lat, lon, time in gps_data:
        dist = haversine_distance(last_lat, last_lon, lat, lon)
        if dist <= max_search_radius_m:
            nearby_gps.append((lat, lon, time))
    
    if len(nearby_gps) < min_visits:
        return []
    
    coords = np.array([[lat, lon] for lat, lon, _ in nearby_gps])
    times = [time for _, _, time in nearby_gps]
    
    coords_radians = np.radians(coords)
    
    clusterer = hdbscan.HDBSCAN(
        min_cluster_size=min_cluster_size,
        min_samples=min_visits,
        metric='haversine',
        cluster_selection_epsilon=0.0,
        cluster_selection_method='eom'
    )
    
    clusterer.fit(coords_radians)
    labels = clusterer.labels_
    
    clusters = []
    for label in set(labels):
        if label == -1:
            continue
        
        cluster_mask = labels == label
        cluster_points = coords[cluster_mask]
        cluster_times = [times[i] for i in range(len(times)) if cluster_mask[i]]
        
        center_lat = cluster_points[:, 0].mean()
        center_lon = cluster_points[:, 1].mean()
        
        total_records = len(cluster_points)
        visit_sessions = count_visit_sessions(cluster_times, gap_threshold_minutes=session_gap_minutes)
        
        try:
            cluster_stability = float(clusterer.cluster_persistence_[label])
        except:
            cluster_stability = 0.5
        
        clusters.append((center_lat, center_lon, visit_sessions, total_records, cluster_stability))
    
    clusters.sort(key=lambda x: x[2], reverse=True)
    
    return clusters


async def find_frequent_locations_with_sessions(gps_data, last_known_coords, max_search_radius_m,
                                                min_visits, session_gap_minutes, min_cluster_size):
    """ë¹„ë™ê¸° ë²„ì „"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        executor,
        find_frequent_locations_with_sessions_sync,
        gps_data, last_known_coords, max_search_radius_m,
        min_visits, session_gap_minutes, min_cluster_size
    )


# =============================================================================
# API Endpoints
# =============================================================================

@app.get("/")
async def root():
    """API ë£¨íŠ¸"""
    return {
        "status": "running",
        "service": "Missing Person Destination Prediction API",
        "version": "11.0.0",
        "endpoints": {
            "/api/predict-destinations": "ì‹¤ì‹œê°„ ëª©ì ì§€ ì˜ˆì¸¡",
            "/api/validate-model": "ëª¨ë¸ ê²€ì¦",
            "/api/health": "í—¬ìŠ¤ ì²´í¬",
            "/docs": "API ë¬¸ì„œ"
        },
        "features": [
            "BallTree ê¸°ë°˜ ë¹ ë¥¸ ë„ë¡œ ë…¸ë“œ ìŠ¤ëƒ…",
            "ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„",
            "ì„ í˜¸ ê²½ë¡œ ë°˜ì˜",
            "ì§€ë¦¬ì  ë¶„ì‚° ê³ ë ¤",
            "ëª¨ë¸ ê²€ì¦ ê¸°ëŠ¥"
        ]
    }


@app.post("/api/predict-destinations", response_model=PredictionResponse)
async def predict_destinations(
    user_no: int = Query(..., description="ì‚¬ìš©ì ë²ˆí˜¸"),
    missing_time: str = Query(..., description="ì‹¤ì¢… ì‹œê°„ (YYYY-MM-DD HH:MM)"),
    analysis_days: int = Query(120, ge=1, le=365, description="ë¶„ì„ ê¸°ê°„ (ì¼)"),
    time_window_hours: int = Query(3, ge=1, le=12, description="ì‹œê°„ëŒ€ í•„í„° (Â±ì‹œê°„)"),
    session_gap: int = Query(30, ge=5, le=120, description="ì„¸ì…˜ êµ¬ë¶„ (ë¶„)"),
    min_cluster_size: int = Query(10, ge=3, le=50, description="ìµœì†Œ í´ëŸ¬ìŠ¤í„° í¬ê¸°"),
    max_search_radius: int = Query(2000, ge=500, le=5000, description="ê²€ìƒ‰ ë°˜ê²½ (m)"),
    min_cluster_separation: int = Query(200, ge=50, le=500, description="í´ëŸ¬ìŠ¤í„° ê°„ ê±°ë¦¬ (m)"),
    road_network_radius: int = Query(2500, ge=1000, le=5000, description="ë„ë¡œë§ ë°˜ê²½ (m)"),
    csv_path: str = Query("all_locations.csv", description="POI CSV")
):
    """
    ì‹¤ì¢…ì ëª©ì ì§€ ì˜ˆì¸¡
    
    ì‹¤ì¢… ì‹œê°„ ì´ì „ì˜ GPS ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ëŠ¥ì„± ë†’ì€ ëª©ì ì§€ì™€ ê²½ë¡œ ì˜ˆì¸¡
    """
    
    print(f"\n{'='*60}")
    print(f"[ì˜ˆì¸¡ ìš”ì²­] user={user_no}, time={missing_time}")
    print(f"{'='*60}")
    
    try:
        target_time = datetime.strptime(missing_time, "%Y-%m-%d %H:%M")
    except ValueError:
        raise HTTPException(status_code=400, detail="ì‹œê°„ í˜•ì‹ ì˜¤ë¥˜ (YYYY-MM-DD HH:MM)")
    
    try:
        pois_df = pd.read_csv(csv_path)
        print(f"âœ… POI: {len(pois_df)}ê°œ")
    except:
        pois_df = pd.DataFrame()
        print(f"âš ï¸ POI íŒŒì¼ ì—†ìŒ")
    
    async with SessionLocal() as session:
        metadata = MetaData()
        locations_table = Table(
            'user_location', metadata,
            Column('location_no', Integer, primary_key=True),
            Column('user_no', Integer),
            Column('latitude', Float),
            Column('longitude', Float),
            Column('record_time', DateTime)
        )
        
        start_time = target_time - timedelta(days=analysis_days)
        end_time = target_time
        
        print(f"ğŸ“… ë¶„ì„ ê¸°ê°„: {analysis_days}ì¼")
        
        query = select(
            locations_table.c.latitude,
            locations_table.c.longitude,
            locations_table.c.record_time
        ).where(
            and_(
                locations_table.c.user_no == user_no,
                locations_table.c.record_time >= start_time,
                locations_table.c.record_time < end_time
            )
        ).order_by(locations_table.c.record_time)
        
        result = await session.execute(query)
        locations = result.fetchall()
        
        if not locations:
            raise HTTPException(status_code=404, detail="GPS ë°ì´í„° ì—†ìŒ")
        
        print(f"âœ… GPS: {len(locations)}ê°œ")
        
        # âœ… ìˆ˜ì •: ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨
        EXPECTED_28DAYS_RECORDS = 3 * 20 * 24 * 28  # ë°ì´í„° ê¸°ê°„ì´ 28ì¼ ë³´ë‹¤ ì ë‹¤ë©´?
        EXPECTED_7DAYS_RECORDS = 3 * 20 * 24 * 7 # ë°ì´í„° ê¸°ê°„ì´ 7ì¼ë³´ë‹¤ ì ë‹¤ë©´?
        if len(locations) < EXPECTED_7DAYS_RECORDS :
            data_sufficiency = "nono"
        elif len(locations) < EXPECTED_28DAYS_RECORDS :
            data_sufficiency = "no"
        else : 
            data_sufficiency = "yes"        
        print(f"âœ… GPS: {len(locations)}ê°œ")
                
        last_location = locations[-1]
        last_lat = last_location.latitude
        last_lon = last_location.longitude
        last_time = last_location.record_time
        
        print(f"ğŸ“ ë§ˆì§€ë§‰ ìœ„ì¹˜: ({last_lat:.6f}, {last_lon:.6f})")
        
        gps_data = [(loc.latitude, loc.longitude, loc.record_time) for loc in locations]
        
        # ì‹œê°„ëŒ€ í•„í„°ë§
        print(f"â° ì‹œê°„ëŒ€ í•„í„°ë§ (Â±{time_window_hours}ì‹œê°„)...")
        time_filtered_gps = filter_by_similar_time(gps_data, target_time, time_window_hours=time_window_hours)
        print(f"âœ… ì‹œê°„ëŒ€ ë°ì´í„°: {len(time_filtered_gps)}ê°œ")
        
        if len(time_filtered_gps) < 100:
            time_filtered_gps = filter_by_similar_time(gps_data, target_time, time_window_hours=6)
            print(f"   ë²”ìœ„ í™•ëŒ€: {len(time_filtered_gps)}ê°œ")
        
        if len(time_filtered_gps) < 50:
            time_filtered_gps = gps_data
            print(f"   ì „ì²´ ì‚¬ìš©: {len(time_filtered_gps)}ê°œ")
        
        # ë„ë¡œë§ ë‹¤ìš´ë¡œë“œ
        print(f"ğŸŒ ë„ë¡œë§ ë¡œë”©...")
        G = await get_road_network(last_lat, last_lon, radius_m=road_network_radius)
        
        # BallTree êµ¬ì¶•
        tree_data = None
        if G is not None:
            print(f"ğŸ”§ BallTree êµ¬ì¶•...")
            tree_data = build_balltree(G)
            print(f"âœ… BallTree ì¤€ë¹„")
        
        # í´ëŸ¬ìŠ¤í„°ë§
        print(f"ğŸ” í´ëŸ¬ìŠ¤í„°ë§...")
        
        all_clusters = await find_frequent_locations_with_sessions(
            time_filtered_gps,
            last_known_coords=(last_lat, last_lon),
            max_search_radius_m=max_search_radius,
            min_visits=5,
            session_gap_minutes=session_gap,
            min_cluster_size=min_cluster_size
        )
        
        print(f"âœ… í´ëŸ¬ìŠ¤í„°: {len(all_clusters)}ê°œ")
        
        if not all_clusters:
            raise HTTPException(status_code=404, detail="í´ëŸ¬ìŠ¤í„° ì—†ìŒ")
        
        # ê±°ë¦¬ë³„ ë¶„ë¥˜
        clusters_by_distance = {"500m": [], "1000m": [], "1500m": []}
        
        for cluster_lat, cluster_lon, visit_sessions, total_records, stability in all_clusters:
            distance = haversine_distance(last_lat, last_lon, cluster_lat, cluster_lon)
            
            if distance < 50:
                continue
            
            cluster_data = (cluster_lat, cluster_lon, visit_sessions, total_records, stability, distance)
            
            if distance <= 500:
                clusters_by_distance["500m"].append(cluster_data)
            elif distance <= 1000:
                clusters_by_distance["1000m"].append(cluster_data)
            elif distance <= 1500:
                clusters_by_distance["1500m"].append(cluster_data)
        
        print(f"\nğŸ“Š ê±°ë¦¬ë³„ ë¶„í¬: 500m({len(clusters_by_distance['500m'])}), "
              f"1000m({len(clusters_by_distance['1000m'])}), 1500m({len(clusters_by_distance['1500m'])})")
        
        # ê° ë²”ìœ„ ì²˜ë¦¬
        destinations_by_distance = {}
        
        for range_key in ["500m", "1000m", "1500m"]:
            print(f"\nğŸ¯ {range_key}...")
            
            selected_clusters = select_diverse_clusters(
                clusters_by_distance[range_key],
                max_count=5,
                min_separation_m=min_cluster_separation
            )
            
            destinations = []
            
            for cluster_lat, cluster_lon, visit_sessions, total_records, stability, distance in selected_clusters:
                waypoints, preference_score, route_method = await generate_road_snapped_waypoints(
                    G,
                    tree_data,
                    time_filtered_gps,
                    last_lat, last_lon,
                    cluster_lat, cluster_lon
                )
                
                print(f"  - {distance:.0f}m, ë°©ë¬¸ {visit_sessions}íšŒ, {route_method}")
                
                poi_name = None
                if not pois_df.empty:
                    for _, poi in pois_df.iterrows():
                        if haversine_distance(cluster_lat, cluster_lon, poi['lat'], poi['lon']) < 100:
                            poi_name = poi['name']
                            break
                
                destination = {
                    "destination_id": len(destinations) + 1,
                    "latitude": float(round(cluster_lat, 6)),
                    "longitude": float(round(cluster_lon, 6)),
                    "visit_count": int(visit_sessions),
                    "total_gps_records": int(total_records),
                    "distance_meters": float(round(distance, 1)),
                    "cluster_stability": float(round(stability, 3)),
                    "waypoints": waypoints,
                    "preference_score": float(round(preference_score, 3)),
                    "route_method": route_method
                }
                
                if poi_name:
                    destination["name"] = poi_name
                
                destinations.append(destination)
            
            destinations_by_distance[range_key] = destinations
        
        print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ!\n")
        
        response_data = {
            "user_no": user_no,
            "missing_time": target_time.isoformat(),
            "last_known_location": {
                "latitude": float(last_lat),
                "longitude": float(last_lon),
                "time": last_time.isoformat()
            },
            "analysis_period_days": analysis_days,
            "session_gap_minutes": session_gap,
            "time_filtered_records": len(time_filtered_gps),
            "total_clusters_found": len(all_clusters),
            "destinations_by_distance": destinations_by_distance,
            "data_sufficiency": data_sufficiency,
            "total_gps_records": len(locations)
        }
        
        return response_data


@app.post("/api/validate-model", response_model=ValidationResponse)
async def validate_model(
    user_no: int = Query(..., description="ì‚¬ìš©ì ë²ˆí˜¸"),
    validation_start: str = Query(..., description="ê²€ì¦ ì‹œì‘ (YYYY-MM-DD HH:MM)"),
    validation_end: str = Query(..., description="ê²€ì¦ ì¢…ë£Œ (YYYY-MM-DD HH:MM)"),
    training_days: int = Query(120, description="í•™ìŠµ ê¸°ê°„ (ì¼)"),
    test_interval_hours: int = Query(24, description="í…ŒìŠ¤íŠ¸ ê°„ê²© (ì‹œê°„)"),
    csv_path: str = Query("all_locations.csv")
):
    """
    ëª¨ë¸ ê²€ì¦
    
    ê³¼ê±° ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    - Hit Rate: ì˜ˆì¸¡ ì •í™•ë„
    - í‰ê·  ê±°ë¦¬ ì˜¤ì°¨
    - ê²½ë¡œ ìœ ì‚¬ë„
    """
    
    print(f"\n{'='*60}")
    print(f"[ê²€ì¦ ì‹œì‘] user={user_no}")
    print(f"ê²€ì¦ ê¸°ê°„: {validation_start} ~ {validation_end}")
    print(f"{'='*60}\n")
    
    try:
        val_start_time = datetime.strptime(validation_start, "%Y-%m-%d %H:%M")
        val_end_time = datetime.strptime(validation_end, "%Y-%m-%d %H:%M")
    except ValueError:
        raise HTTPException(status_code=400, detail="ì‹œê°„ í˜•ì‹ ì˜¤ë¥˜")
    
    try:
        pois_df = pd.read_csv(csv_path)
    except:
        pois_df = pd.DataFrame()
    
    async with SessionLocal() as session:
        metadata = MetaData()
        locations_table = Table(
            'user_location', metadata,
            Column('location_no', Integer, primary_key=True),
            Column('user_no', Integer),
            Column('latitude', Float),
            Column('longitude', Float),
            Column('record_time', DateTime)
        )
        
        # ì „ì²´ ë°ì´í„° ë¡œë“œ
        full_start = val_start_time - timedelta(days=training_days)
        full_end = val_end_time
        
        query = select(
            locations_table.c.latitude,
            locations_table.c.longitude,
            locations_table.c.record_time
        ).where(
            and_(
                locations_table.c.user_no == user_no,
                locations_table.c.record_time >= full_start,
                locations_table.c.record_time <= full_end
            )
        ).order_by(locations_table.c.record_time)
        
        result = await session.execute(query)
        all_locations = result.fetchall()
        
        if not all_locations:
            raise HTTPException(status_code=404, detail="ë°ì´í„° ì—†ìŒ")
        
        print(f"âœ… ì „ì²´ ë°ì´í„°: {len(all_locations)}ê°œ")
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±
        test_times = []
        current_test_time = val_start_time
        while current_test_time <= val_end_time:
            test_times.append(current_test_time)
            current_test_time += timedelta(hours=test_interval_hours)
        
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(test_times)}ê°œ\n")
        
        # ê²€ì¦ ì§€í‘œ
        hits_500m = 0
        hits_1000m = 0
        hits_1500m = 0
        distance_errors = []
        route_similarities = []
        test_cases = []
        
        for test_idx, test_time in enumerate(test_times):
            print(f"[í…ŒìŠ¤íŠ¸ {test_idx+1}/{len(test_times)}] {test_time.strftime('%Y-%m-%d %H:%M')}")
            
            # í•™ìŠµ ë°ì´í„°
            train_start = test_time - timedelta(days=training_days)
            train_end = test_time
            
            train_data = [
                (loc.latitude, loc.longitude, loc.record_time)
                for loc in all_locations
                if train_start <= loc.record_time < train_end
            ]
            
            if len(train_data) < 100:
                print(f"  âš ï¸ í•™ìŠµ ë°ì´í„° ë¶€ì¡±, ìŠ¤í‚µ")
                continue
            
            # ë§ˆì§€ë§‰ ìœ„ì¹˜
            last_lat, last_lon, last_time = train_data[-1]
            
            # ì‹œê°„ëŒ€ë³„ í•„í„°ë§
            time_filtered = filter_by_similar_time(train_data, test_time, time_window_hours=3)
            
            if len(time_filtered) < 50:
                time_filtered = train_data
            
            # í´ëŸ¬ìŠ¤í„°ë§
            try:
                clusters = await find_frequent_locations_with_sessions(
                    time_filtered,
                    last_known_coords=(last_lat, last_lon),
                    max_search_radius_m=2000,
                    min_visits=5,
                    session_gap_minutes=30,
                    min_cluster_size=10
                )
            except Exception as e:
                print(f"  âš ï¸ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}, ìŠ¤í‚µ")
                continue
            
            if not clusters:
                print(f"  âš ï¸ í´ëŸ¬ìŠ¤í„° ì—†ìŒ, ìŠ¤í‚µ")
                continue
            
            # ì˜ˆì¸¡: ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ëª©ì ì§€
            pred_lat, pred_lon = clusters[0][0], clusters[0][1]
            
            # ì‹¤ì œ ë°ì´í„°: ë¯¸ë˜ 6ì‹œê°„
            actual_future_data = [
                (loc.latitude, loc.longitude, loc.record_time)
                for loc in all_locations
                if test_time <= loc.record_time < test_time + timedelta(hours=6)
            ]
            
            if len(actual_future_data) < 10:
                print(f"  âš ï¸ ì‹¤ì œ ë°ì´í„° ë¶€ì¡±, ìŠ¤í‚µ")
                continue
            
            # ì‹¤ì œ ëª©ì ì§€
            try:
                actual_clusters = await find_frequent_locations_with_sessions(
                    actual_future_data,
                    last_known_coords=(last_lat, last_lon),
                    max_search_radius_m=2000,
                    min_visits=3,
                    session_gap_minutes=30,
                    min_cluster_size=5
                )
            except Exception as e:
                print(f"  âš ï¸ ì‹¤ì œ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨, ìŠ¤í‚µ")
                continue
            
            if not actual_clusters:
                print(f"  âš ï¸ ì‹¤ì œ í´ëŸ¬ìŠ¤í„° ì—†ìŒ, ìŠ¤í‚µ")
                continue
            
            actual_lat, actual_lon = actual_clusters[0][0], actual_clusters[0][1]
            
            # ê±°ë¦¬ ì˜¤ì°¨
            distance_error = haversine_distance(pred_lat, pred_lon, actual_lat, actual_lon)
            distance_errors.append(distance_error)
            
            # Hit rate
            hit_500 = distance_error <= 500
            hit_1000 = distance_error <= 1000
            hit_1500 = distance_error <= 1500
            
            if hit_500:
                hits_500m += 1
                hits_1000m += 1
                hits_1500m += 1
            elif hit_1000:
                hits_1000m += 1
                hits_1500m += 1
            elif hit_1500:
                hits_1500m += 1
            
            # ê²½ë¡œ ìœ ì‚¬ë„ (ì˜ˆì¸¡ ìœ„ì¹˜ ê·¼ì²˜ í†µê³¼ ì—¬ë¶€)
            passed_near = any(
                haversine_distance(pred_lat, pred_lon, gps_lat, gps_lon) <= 100
                for gps_lat, gps_lon, gps_time in actual_future_data
            )
            route_similarities.append(1.0 if passed_near else 0.0)
            
            # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì €ì¥
            test_cases.append({
                "test_time": test_time.isoformat(),
                "predicted_location": {"lat": float(pred_lat), "lon": float(pred_lon)},
                "actual_location": {"lat": float(actual_lat), "lon": float(actual_lon)},
                "distance_error": float(round(distance_error, 1)),
                "hit_500m": hit_500,
                "hit_1000m": hit_1000,
                "hit_1500m": hit_1500
            })
            
            print(f"  âœ“ ì˜¤ì°¨: {distance_error:.0f}m")
        
        total_tests = len(test_cases)
        
        if total_tests == 0:
            raise HTTPException(status_code=404, detail="ìœ íš¨í•œ í…ŒìŠ¤íŠ¸ ì—†ìŒ")
        
        # ê²€ì¦ ì§€í‘œ ê³„ì‚°
        metrics = {
            "total_test_cases": total_tests,
            "hit_rate_500m": float(round(hits_500m / total_tests, 3)),
            "hit_rate_1000m": float(round(hits_1000m / total_tests, 3)),
            "hit_rate_1500m": float(round(hits_1500m / total_tests, 3)),
            "average_distance_error": float(round(np.mean(distance_errors), 1)),
            "median_distance_error": float(round(np.median(distance_errors), 1)),
            "route_similarity_score": float(round(np.mean(route_similarities), 3))
        }
        
        print(f"\n{'='*60}")
        print(f"ê²€ì¦ ê²°ê³¼")
        print(f"{'='*60}")
        print(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
        print(f"500m ì ì¤‘ë¥ : {metrics['hit_rate_500m']*100:.1f}%")
        print(f"1000m ì ì¤‘ë¥ : {metrics['hit_rate_1000m']*100:.1f}%")
        print(f"1500m ì ì¤‘ë¥ : {metrics['hit_rate_1500m']*100:.1f}%")
        print(f"í‰ê·  ì˜¤ì°¨: {metrics['average_distance_error']:.0f}m")
        print(f"ì¤‘ê°„ê°’ ì˜¤ì°¨: {metrics['median_distance_error']:.0f}m")
        print(f"ê²½ë¡œ ìœ ì‚¬ë„: {metrics['route_similarity_score']:.2f}")
        print(f"{'='*60}\n")
        
        response = {
            "user_no": user_no,
            "validation_period": f"{validation_start} ~ {validation_end}",
            "metrics": metrics,
            "test_cases": test_cases[:20]  # ìµœëŒ€ 20ê°œ
        }
        
        return response


@app.get("/api/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    try:
        async with SessionLocal() as session:
            await session.execute(select(1))
        return {
            "status": "healthy",
            "database": "connected",
            "version": "11.0.0",
            "features": [
                "BallTree optimization",
                "Time-based filtering",
                "Road network snapping",
                "Model validation"
            ]
        }
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}


# =============================================================================
# Main
# =============================================================================

if __name__ == "__main__":
    import uvicorn
    print("="*60)
    print("ğŸš€ ì‹¤ì¢…ì ëª©ì ì§€ ì˜ˆì¸¡ API ì‹œì‘")
    print("="*60)
    print("ğŸ“– ë¬¸ì„œ: http://0.0.0.0:8000/docs")
    print("ğŸ” ì˜ˆì¸¡: POST /api/predict-destinations")
    print("ğŸ“Š ê²€ì¦: POST /api/validate-model")
    print("ğŸ’š í—¬ìŠ¤: GET /api/health")
    print("="*60)
    uvicorn.run(app, host="0.0.0.0", port=8000)
